import streamlit as st
import pandas as pd
import openai
import os
import datetime
import base64
import requests
import json
import re
import glob

title = "ğŸ† Open-Ko-Finance-LLM-Leaderboard"
st.set_page_config(
    page_title=title,
    page_icon="ğŸ†",
    layout="wide",
)

# Load the API key from Streamlit secrets
try:
    github_token = st.secrets['GITHUB_TOKEN']
except KeyError:
    st.error("GITHUB_TOKEN í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'Manage app'ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

def upload_to_github(token, repo, path, content):
    url = f"https://api.github.com/repos/{repo}/contents/{path}"
    headers = {
        "Authorization": f"token {token}",
        "Content-Type": "application/json"
    }
    
    # ë¨¼ì € íŒŒì¼ì˜ sha ê°’ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ GET ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        sha = response.json().get('sha')
    else:
        sha = None

    data = {
        "message": "Add inference result",
        "content": base64.b64encode(content.encode()).decode()
    }
    if sha:
        data["sha"] = sha

    # íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ PUT ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
    response = requests.put(url, headers=headers, json=data)
    if response.status_code == 201:
        st.success("ì¶”ë¡  ì™„ë£Œ")
    elif response.status_code == 200:
        st.success("íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        st.error(f"ì¶”ë¡  ì‹¤íŒ¨: {response.status_code} - {response.json().get('message', 'Unknown error')}")
        st.error(response.json())  # ì¶”ê°€ì ìœ¼ë¡œ ì „ì²´ ì‘ë‹µ ë‚´ìš©ì„ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹…ì— ë„ì›€

def setup_basic():
    url = 'https://personaai.co.kr/main'
    st.title(title)

    st.markdown(
        "ğŸš€ Open-Ko-Finance-LLM ë¦¬ë”ë³´ë“œëŠ” í•œêµ­ì–´ ê¸ˆìœµ ë¶„ì•¼ì˜ ì „ë¬¸ì ì¸ ì§€ì‹ì„ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ë¡œ ê°ê´€ì ì¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n"
    )
    st.markdown( f" ì´ ë¦¬ë”ë³´ë“œëŠ” [(ì£¼)í˜ë¥´ì†Œë‚˜ì—ì´ì•„ì´](https://personaai.co.kr/main)ì—ì„œ ìš´ì˜í•©ë‹ˆë‹¤.")

def setup_about():
    css = '''
    <style>
        .stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
        font-size:1.5rem;
    </style>
    <style>
    .stButton button {
        font-size: 20px;
        padding: 10px 783px;
        background : linear-gradient(to right, #F2F3F4, #F5F6F7)
        
    }
    .stButton button:hover {
        background: linear-gradient(to right, #DEE1E3, #F2F3F4);
    }
    </style>
    '''

    st.markdown(css, unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["ğŸ“– About", "ğŸš€Submit here!", "ğŸ… LLM BenchMark"])
    with tab1:
        st.markdown('<h3>ì£¼ì œ ê°œìš”</h3>', unsafe_allow_html=True)
        st.markdown('ìµœê·¼ ì¸ê³µì§€ëŠ¥(AI) ê¸°ìˆ ì˜ ë°œì „ì€ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì— ê±¸ì³ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤.')
        st.markdown('íŠ¹íˆ, ìƒì„±í˜• AI ê¸°ìˆ ì˜ ë„ì…ì€ ìì—°ì–´ ì²˜ë¦¬(NLP)ì™€ ê´€ë ¨ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆëŠ”ë°,')
        st.markdown('ê¸ˆìœµ ìƒë‹´ ì„œë¹„ìŠ¤ ë¶„ì•¼ì—ì„œë„ AIë¥¼ í™œìš©í•œ ìë™í™”ëœ ìƒë‹´ ì‹œìŠ¤í…œì€ ë¹„ìš© ì ˆê°ê³¼ ì„œë¹„ìŠ¤ íš¨ìœ¨ì„± í–¥ìƒì„ ëª©í‘œë¡œ í™œë°œíˆ ì—°êµ¬ë˜ê³  ìˆìŠµë‹ˆë‹¤.')
        st.markdown('ì´ëŸ¬í•œ ë°°ê²½ ì†ì—ì„œ ìƒì„±í˜• AIë¥¼ í™œìš©í•œ ê¸ˆìœµ ìƒë‹´ Chat-Bot ê°œë°œì„ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ìµœì í™”ì™€ ê¸ˆìœµ ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ê²½í—˜ì„ ê°œì„ í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.')
        st.write('')
        st.markdown('<h5>í‰ê°€ ë°©ì‹</h5>', unsafe_allow_html=True)
        st.markdown('ğŸ“ˆ ìš°ë¦¬ëŠ” [LogicKor](https://github.com/instructkr/LogicKor) ë‹¤ë¶„ì•¼ ì‚¬ê³ ë ¥ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ë¥¼ í™œìš©í•˜ì—¬ ê¸ˆìœµ ë„ë©”ì¸ì— LLM ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤. ')
        st.markdown('í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ ë°ì´í„° ì„¸íŠ¸ì™€ í•œêµ­ì–´ ì›¹ ì½”í¼ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì—¬, 3ê°€ì§€ ì‘ì—…(FIQUSA, MMLU_F, MATHQA)ë¥¼ êµ¬ì¶•í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì²˜ìŒë¶€í„° ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.')
        st.markdown('LLM ì‹œëŒ€ì— ê±¸ë§ì€ í‰ê°€ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ í•´ë‹¹ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì±„íƒí•˜ì˜€ê³ , ìµœì¢… ì ìˆ˜ëŠ” ê° í‰ê°€ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì–»ì€ í‰ê·  ì ìˆ˜ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.')
        st.write('')
        st.markdown('<h5>í‰ê°€ ê¸°ì¤€ ì„¤ëª…</h5>', unsafe_allow_html=True)
        st.markdown('1ï¸âƒ£ FIQUSA : ê¸ˆìœµ ë„ë©”ì¸ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì˜ ê°ì„±ì„ ì˜ˆì¸¡í•˜ì—¬ ì‹œì¥ ë™í–¥ì„ íŒŒì•…í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ì…ë‹ˆë‹¤.')
        st.markdown('2ï¸âƒ£ MMLU_F : ê¸ˆìœµ ê´€ë ¨ ë„ë©”ì¸ì„ ì •í™•í•˜ê²Œ ì´í•´í•˜ê³  ìˆëŠ”ì§€, ê°ê´€ì‹ í˜•íƒœë¡œ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ì…ë‹ˆë‹¤.')
        st.markdown('3ï¸âƒ£ MATHQA : ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì˜µì…˜ ê°€ê²© ëª¨ë¸ë§ ë“± ê¸ˆìœµ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ìˆ˜ë¦¬ì  ë¬¸ì œë¥¼ ì˜ í•´ê²°í•˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ì…ë‹ˆë‹¤.')
        st.write('')
        st.markdown('<h5>ê´€ë ¨ ë¬¸ì˜ì‚¬í•­</h5>', unsafe_allow_html=True)
        st.markdown('í‰ê°€ ì˜ˆì‹œ ë°ì´í„°ì…‹ê³¼ Chatgpt ì‚¬ìš© ê´€ë ¨ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ anstmdwn45@personaai.co.krë¡œ ì—°ë½ì£¼ì„¸ìš” ğŸ¤©')
        st.markdown('Made with â¤ï¸ by the awesome open-source community from all over ğŸŒ')
        st.write('')
        st.write('')
        st.write('')

    with tab2:
        code2 = '''
# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ë¡œë“œ
import openai

# 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (gpt-api key ì„¤ì •)
client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY", "API_KEY ì…ë ¥"))

# 3. ëª¨ë¸ ì¶”ë¡ ìˆ˜í–‰
messages = [
    {"role": "system", "content": 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.'},
    {"role": "user", "content": str(question)}
    ]

response = client.chat.completions.create(
    model=selected_option,
    messages=messages,
    max_tokens=4096) # ìµœëŒ€ 4k 

result = response.choices[0].message.content

'''
        code = '''
# 1. í•„ìš” ê°œë°œí™˜ê²½ ì„¤ì¹˜ (Colab, Jupyter)
!pip install openai

# 2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ë¡œë“œ
import openai
import os

# 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (gpt-api key ì„¤ì •)
client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY", "API_KEY ì…ë ¥"))

# 4. openai playground í•™ìŠµ ë°ì´í„° ì—…ë¡œë“œ
def data_loader(train_file):
    with open(train_file, 'rb') as train_ft:
        training_response = client.files.create(file = train_ft, purpose='fine-tune')
        train_file_id = training_response.id
        
# 5. gpt-3.5-turbo ë¯¸ì„¸ì¡°ì •
def gpt_finetuning():
    response = client.fine_tuning.jobs.create(
        training_file=training_file_id,
        model="ëª¨ë¸ëª…", # gpt-4-o-mini, gpt-3.5-turbo
        suffix="Finance_íŒ€ì´ë¦„",
        hyperparameters={
            "n_epochs": 3, # ë°ì´í„° ë°˜ë³µ íšŸìˆ˜ / ì£¼ë¡œ 3~5ë¡œ ì„¤ì •
	    "batch_size": 3, # í•œ ë²ˆì˜ í•™ìŠµì— ì²˜ë¦¬ í•  ë°ì´í„° ìˆ˜
	    "learning_rate_multiplier": 0.3 # ëª¨ë¸ì˜ í•™ìŠµë¥  : ê²½ì‚¬í•˜ê°•ë²•ì„ í†µí•´, ëª¨ë¸ì´ ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™” í•  ìˆ˜ ìˆëŠ” ë°©í–¥ì„ ì„¤ì •
        })
        '''
        st.markdown('<h3>Evaluation Queue for the ğŸš€ Open Ko-LLM Leaderboard</h3>', unsafe_allow_html=True)
        st.markdown('1ï¸âƒ£ ChatGPTë¥¼ í™œìš©í•˜ì—¬ ë¯¸ì„¸ ì¡°ì •ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•')
        st.code(code, language='python')
        st.markdown('2ï¸âƒ£ ë§Œì•½ì— ë°ì´í„° ë° ëª¨ë¸ì„ ì—…ë¡œë“œ í•˜ì˜€ëŠ”ë°, ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤ë©´ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ë³´ì„¸ìš”')
        st.markdown('âš ï¸ gpt modelì„ íŒŒì¸íŠœë‹ í•˜ê¸°ìœ„í•´ì„œëŠ” ìœ„ì—ì„œ ì •ì˜í•œ Chat-Completion ë°ì´í„° í˜•ì‹ì„ ìœ ì§€í•´ì•¼í•©ë‹ˆë‹¤.â—')
        st.markdown('âš ï¸ Fine Tuningì„ í•œ ëª¨ë¸ ê³„ì •ì˜ APIë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ì§€ ì•Šì„ê²½ìš° ì œëŒ€ë¡œ ëœ í‰ê°€ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.â—')
        st.markdown('âš ï¸ OpenAPI Keyë¥¼ í™•ì¸í•´ë³´ì„¸ìš”. ì¢…ì¢… API Keyë¥¼ ì˜ëª» ì…ë ¥í•œ ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ğŸ¤£')
        st.markdown('')
        st.markdown('3ï¸âƒ£ ëª¨ë¸ í‰ê°€ ë°©ë²•ì€ ì•„ë˜ ë©”ë‰´ì–¼ ëŒ€ë¡œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤.')
        st.markdown('â€¢ Expander 1ì„ í´ë¦­í•˜ì—¬ íŒŒì¸íŠœë‹ì„ ìˆ˜í–‰í•œ ëª¨ë¸ì´ë¦„ê³¼ OpenAI API Keyë¥¼ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤.')
        st.markdown('â€¢ Expander 2ë¥¼ í´ë¦­í•˜ì—¬ íŒ€ ì´ë¦„ê³¼ ëª¨ë¸ íƒ€ì…ì„ ì„¤ì •í•˜ëŠ”ë°, íŒ€ ì´ë¦„ì€ ìµœì¢… ëª¨ë¸ í‰ê°€ ê³¼ì •ì—ì„œ í•„ìš”í•œ ì‚¬í•­ì´ë‹ˆ ë°˜ë“œì‹œ ì…ë ¥í•´ì£¼ì„¸ìš” â—')
        st.markdown('â€¢ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ”ë° ëŒ€ì²´ë¡œ 10ë¶„ ì´ìƒ ì†Œìš” ë©ë‹ˆë‹¤ ğŸ˜Š ê·¸ ì‹œê°„ë™ì•ˆ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ êµ¬ì„±í•´ë³´ì„¸ìš” ')
        st.markdown('â€¢ ì¶”ë¡ ì´ ëë‚˜ë©´ ì•„ë˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬, íŒŒì¸íŠœë‹ ëœ ChatGpt ëª¨ë¸ì˜ ì¶œë ¥ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
        st.markdown('4ï¸âƒ£ ë¯¸ì„¸ì¡°ì •ëœ ChatGPTë¥¼ í™œìš©í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•')
        st.code(code2, language='python')
        st.markdown('')
        
        with st.form(key='inference_form_1'):  # ê³ ìœ í•œ í‚¤ ë¶€ì—¬
            st.subheader('ğŸ“‹ ì¸í¼ëŸ°ìŠ¤ ê²°ê³¼ ìƒì„±')

            # í…ìŠ¤íŠ¸ ì…ë ¥ ìƒì
            col1, col2 = st.columns([0.54, 0.46])
            
            with col1:
                with st.expander('Expander 1'):
                    selected_option = st.text_input(
                        "ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.", 
                        placeholder='ì—¬ê¸°ì— ì…ë ¥í•´ì£¼ì„¸ìš”',
                        help='ëª¨ë¸ëª… ì˜ˆì‹œ ft:gpt-ëª¨ë¸ëª…:personal:íŒŒì¸íŠœë‹ ëª¨ë¸ëª…'
                    )
                    api_key = st.text_input(
                        label='OpenAPI Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.', 
                        max_chars=100, 
                        type='password',
                        placeholder='ì—¬ê¸°ì— ì…ë ¥í•´ì£¼ì„¸ìš”',
                        help='sk-xxxxxxxxxxxxxx'
                    )
                    client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY", api_key))

            with col2:
                with st.expander('Expander 2'):
                    selected_option_name = st.text_input(
                        "ì†Œì† íŒ€ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.", 
                        placeholder='ì†Œì†íŒ€ì€ ë°˜ë“œì‹œ íŒ€ì´ë¦„-ì œì¶œì‹œê°„ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”',
                        help = 'ex) ì „ë‚¨ëŒ€-15'
                    )
                    selected_option_type = st.selectbox(
                        "ëª¨ë¸ íƒ€ì…ì„ ì…ë ¥í•˜ì„¸ìš”.",
                        ("ğŸŸ¢ gpt-3.5-turbo", "â­• gpt-4-o-mini")
                    )


            if st.form_submit_button('ì¶”ë¡  ì‹œì‘í•˜ê¸°!'):
                with st.spinner():
                    df_questions = pd.read_json('FinBench_Final.jsonl', lines=True)
                    single_turn_outputs = []
                    for question in df_questions['questions']:
                        messages = [
                            {"role": "system", "content": 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.'},
                            {"role": "user", "content": str(question)}
                        ]
                        response = client.chat.completions.create(
                            model=selected_option,
                            messages=messages,
                            max_tokens=4096
                        )
                        single_turn_outputs.append(response.choices[0].message.content)

                    df_output = pd.DataFrame({
                        'id': df_questions['id'],
                        'category': df_questions['category'],
                        'questions': df_questions['questions'],
                        'outputs': single_turn_outputs,
                        'references': df_questions['references']
                    })

                    json_output = df_output.to_json(orient='records', lines=True, force_ascii=False)
                    st.session_state['json_output'] = json_output
                    st.session_state['selected_option_name'] = selected_option_name
                    upload_to_github(github_token, "NUMCHCOMCH/Kor_Finance-leaderboard", f"./data/{st.session_state['selected_option_name'].replace('/', '_')}.json", json_output)

        if 'json_output' in st.session_state:
            st.download_button(
                label='ì¶”ë¡  ê²°ê³¼ ë‹¤ìš´ë¡œë“œ í•˜ê¸°',
                data=st.session_state['json_output'],
                file_name=f"{st.session_state['selected_option_name'].replace('/', '_')}.jsonl",
                mime='text/json'
            )
         
    with tab3:
        st.markdown('<h5> ğŸ‘©â€âœˆï¸ ì „ë‚¨ëŒ€ ê¸ˆìœµ LLM ë¦¬ë”ë³´ë“œ í‰ê°€ ê·œì¹™</h5>', unsafe_allow_html=True)
        st.markdown('1ï¸âƒ£ ì ìˆ˜ ì‚°ì¶œì€ 3ê°€ì§€ ì§€í‘œ(MMLU_F, FIQUSA, MATHQA) ì ìˆ˜ì˜ í‰ê· ìœ¼ë¡œ ì‚°ì¶œí•©ë‹ˆë‹¤.')
        st.markdown('2ï¸âƒ£ MMLU_Fì™€ MATHQAì˜ ê²½ìš° ê¸ˆìœµ ë„ë©”ì¸ ì§€ì‹ê³¼ ë³µì¡í•œ ì¶”ë¡ ì´ í•„ìš”í•˜ë¯€ë¡œ ê°€ì‚°ì ì´ ìˆìŠµë‹ˆë‹¤.ğŸ˜˜')
        st.markdown('3ï¸âƒ£ ì›í™œí•œ ì„œë¹„ìŠ¤ ê°œë°œì„ ìœ„í•´ì„œ ëª¨ë¸ ì œì¶œì€ í•˜ë£¨ ìµœëŒ€ 2ë²ˆê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨â—ë§ˆì§€ë§‰ë‚ ì€ ì›í™œí•œ ì§„í–‰ì„ ìœ„í•´ 1ë²ˆë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ')

        # DataFrame ìƒì„±
        st.markdown('')
        st.subheader('LLM ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬')
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ì§‘ê³„ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        category_scores = {}

        # ì „ì²´ ì‹±ê¸€ ì ìˆ˜ì™€ ë©€í‹° ì ìˆ˜ì˜ ë¦¬ìŠ¤íŠ¸
        total_single_scores = []

        file_path  = './streamlit/ì „ë‚¨ëŒ€-12.jsonl'
        file_path2 = './streamlit/ì „ë‚¨ëŒ€2-12.jsonl'
	    file_path3 = './streamlit/cpm.json'

        def extract_team_and_number(filename):
            base_name = os.path.splitext(filename)[0]
            match = re.match(r'(.*?)-(\d+)', base_name)
            if match:
                return match.group(1), match.group(2)
            return base_name, ''

        # ì§€ì •ëœ íŒ¨í„´ì— ë§ëŠ” ëª¨ë“  íŒŒì¼ì„ ì°¾ì•„ì„œ ì²˜ë¦¬
        def process_file_to_dataframe(file_path):
            category_scores = {} 
            with open(file_path, 'r', encoding='utf-8-sig') as file:  # 'utf-8-sig'ë¡œ ì¸ì½”ë”© ë³€ê²½
                for line in file:
                    item = json.loads(line)
                    category = item['category']
                    single_score = item['query_single']['judge_score']
        
                    if category not in category_scores:
                        category_scores[category] = []
                
                    category_scores[category].append(single_score)

            # ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            avg_scores = {category: (sum(scores) / len(scores)) if scores else 0 for category, scores in category_scores.items()}

            # MMLU_Fì™€ MATHQAì— ê°€ì¤‘ì¹˜ ì ìš©
            if 'MMLU_F' in avg_scores:
                avg_scores['MMLU_F'] *= 1.1
            if 'MATHQA' in avg_scores:
                avg_scores['MATHQA'] *= 1.1
    
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df = pd.DataFrame([avg_scores])
            
            # íŒŒì¼ ì´ë¦„ì—ì„œ íŒ€ ì´ë¦„ê³¼ ëª¨ë¸ ì œì¶œ ë²ˆí˜¸ ì¶”ì¶œ
            team_name, submission_number = extract_team_and_number(os.path.basename(file_path))
            df['íŒ€ì´ë¦„'] = team_name
            df['ëª¨ë¸ ì œì¶œì¼ì‹œ'] = submission_number
            df['AVG_Score'] = ((df['MMLU_F'] + df['FIQUSA'] + df['MATHQA'])/3).round(3)

            return df
        
        # ì†Œìˆ˜ì  í•œ ìë¦¬ë¡œ ì„¤ì •
        pd.options.display.float_format = "{:.1f}".format
        df = process_file_to_dataframe(file_path)
        df_2 = process_file_to_dataframe(file_path2)
	df_3 = process_file_to_dataframe(file_path3)
        df = pd.concat([df,df_2]).sort_values('AVG_Score',ascending=False).reset_index(drop=True)
	df = pd.concat([df,df_3]).sort_values('AVG_Score',ascending=False).reset_index(drop=True)
        df['ëª¨ë¸ ì œì¶œì¼ì‹œ'] = now = datetime.datetime.now().strftime("%Y.%m.%d") +' '+ df['ëª¨ë¸ ì œì¶œì¼ì‹œ'] + ':00'
        df = df[['íŒ€ì´ë¦„','MMLU_F','FIQUSA','MATHQA','AVG_Score','ëª¨ë¸ ì œì¶œì¼ì‹œ']]
        st.dataframe(df,use_container_width=True)

def main():
    setup_basic()
    setup_about()
    
if __name__ == "__main__":
    main()
