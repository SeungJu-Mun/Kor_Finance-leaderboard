import streamlit as st
import pandas as pd
import openai
import os
import datetime
import base64
import requests
import json
import re
import glob

# í˜ì´ì§€ ì„¤ì •
title = "ğŸ¤— AICOSS ì‚°í•™ì—°ê³„ í•´ì»¤í†¤ - ìƒì„±í˜• AIë¥¼ í™œìš©í•œ ê¸ˆìœµ ìƒë‹´ Chat-Bot ê°œë°œ"
st.set_page_config(
    page_title=title,
    page_icon="ğŸ¤—",
    layout="wide",
)

# Load the API key from Streamlit secrets
try:
    github_token = st.secrets['GITHUB_TOKEN']
except KeyError:
    st.error("GITHUB_TOKEN í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'Manage app'ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

def upload_to_github(token, repo, path, content):
    url = f"https://api.github.com/repos/{repo}/contents/{path}"
    headers = {
        "Authorization": f"token {token}",
        "Content-Type": "application/json"
    }
    
    # ë¨¼ì € íŒŒì¼ì˜ sha ê°’ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ GET ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        sha = response.json().get('sha')
    else:
        sha = None

    data = {
        "message": "Add inference result",
        "content": base64.b64encode(content.encode()).decode()
    }
    if sha:
        data["sha"] = sha

    # íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ PUT ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
    response = requests.put(url, headers=headers, json=data)
    if response.status_code == 201:
        st.success("í‰ê°€ ì™„ë£Œ")
    elif response.status_code == 200:
        st.success("íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        st.error(f"í‰ê°€ ì‹¤íŒ¨: {response.status_code} - {response.json().get('message', 'Unknown error')}")
        st.error(response.json())  # ì¶”ê°€ì ìœ¼ë¡œ ì „ì²´ ì‘ë‹µ ë‚´ìš©ì„ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹…ì— ë„ì›€

def setup_basic():
    url = 'https://personaai.co.kr/main'
    st.title(title)

   # ì¶”ê°€ ì„œë¸Œì œëª©
    st.subheader("ğŸ† Open-Ko-Finance-LLM-Leaderboard")

    st.markdown(
        "ğŸš€ Open-Ko-Finance-LLM ë¦¬ë”ë³´ë“œëŠ” í•œêµ­ì–´ ê¸ˆìœµ ë¶„ì•¼ì˜ ì „ë¬¸ì ì¸ ì§€ì‹ì„ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ë¡œ ê°ê´€ì ì¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n"
    )
    st.markdown( f" ì´ ë¦¬ë”ë³´ë“œëŠ” [(ì£¼)í˜ë¥´ì†Œë‚˜ì—ì´ì•„ì´](https://personaai.co.kr/main)ì—ì„œ ìš´ì˜í•©ë‹ˆë‹¤.")

def setup_about():
    css = '''
    <style>
        .stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
        font-size:1.5rem;
    </style>
    <style>
    .stButton button {
        font-size: 20px;
        padding: 10px 783px;
        background : linear-gradient(to right, #F2F3F4, #F5F6F7)
        
    }
    .stButton button:hover {
        background: linear-gradient(to right, #DEE1E3, #F2F3F4);
    }
    </style>
    '''

    st.markdown(css, unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["ğŸ“– About", "ğŸš€Submit here!", "ğŸ… LLM BenchMark"])
    with tab1:
        st.markdown('<h3>ì£¼ì œ ê°œìš”</h3>', unsafe_allow_html=True)
        st.markdown('ìµœê·¼ ì¸ê³µì§€ëŠ¥(AI) ê¸°ìˆ ì˜ ë°œì „ì€ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì— ê±¸ì³ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤.')
        st.markdown('íŠ¹íˆ, ìƒì„±í˜• AI ê¸°ìˆ ì˜ ë„ì…ì€ ìì—°ì–´ ì²˜ë¦¬(NLP)ì™€ ê´€ë ¨ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆëŠ”ë°,')
        st.markdown('ê¸ˆìœµ ìƒë‹´ ì„œë¹„ìŠ¤ ë¶„ì•¼ì—ì„œë„ AIë¥¼ í™œìš©í•œ ìë™í™”ëœ ìƒë‹´ ì‹œìŠ¤í…œì€ ë¹„ìš© ì ˆê°ê³¼ ì„œë¹„ìŠ¤ íš¨ìœ¨ì„± í–¥ìƒì„ ëª©í‘œë¡œ í™œë°œíˆ ì—°êµ¬ë˜ê³  ìˆìŠµë‹ˆë‹¤.')
        st.markdown('ì´ëŸ¬í•œ ë°°ê²½ ì†ì—ì„œ ìƒì„±í˜• AIë¥¼ í™œìš©í•œ ê¸ˆìœµ ìƒë‹´ Chat-Bot ê°œë°œì„ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ìµœì í™”ì™€ ê¸ˆìœµ ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ê²½í—˜ì„ ê°œì„ í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.')
        st.write('')
        st.markdown('<h5>í‰ê°€ ë°©ì‹</h5>', unsafe_allow_html=True)
        st.markdown('ğŸ“ˆ ìš°ë¦¬ëŠ” [LogicKor](https://github.com/instructkr/LogicKor) ë‹¤ë¶„ì•¼ ì‚¬ê³ ë ¥ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ë¥¼ í™œìš©í•˜ì—¬ ê¸ˆìœµ ë„ë©”ì¸ì— LLM ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤. ')
        st.markdown('í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ ë°ì´í„° ì„¸íŠ¸ì™€ í•œêµ­ì–´ ì›¹ ì½”í¼ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì—¬, 3ê°€ì§€ ì‘ì—…(FIQUSA, MMLU_F, MATHQA)ë¥¼ êµ¬ì¶•í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì²˜ìŒë¶€í„° ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.')
        st.markdown('LLM ì‹œëŒ€ì— ê±¸ë§ì€ í‰ê°€ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ í•´ë‹¹ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì±„íƒí•˜ì˜€ê³ , ìµœì¢… ì ìˆ˜ëŠ” ê° í‰ê°€ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì–»ì€ í‰ê·  ì ìˆ˜ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.')
        st.write('')
        st.markdown('<h5>í‰ê°€ ê¸°ì¤€ ì„¤ëª…</h5>', unsafe_allow_html=True)
        st.markdown('1ï¸âƒ£ FIQUSA : ê¸ˆìœµ ë„ë©”ì¸ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì˜ ê°ì„±ì„ ì˜ˆì¸¡í•˜ì—¬ ì‹œì¥ ë™í–¥ì„ íŒŒì•…í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ì…ë‹ˆë‹¤.')
        st.markdown('2ï¸âƒ£ MMLU_F : ê¸ˆìœµ ê´€ë ¨ ë„ë©”ì¸ì„ ì •í™•í•˜ê²Œ ì´í•´í•˜ê³  ìˆëŠ”ì§€, ê°ê´€ì‹ í˜•íƒœë¡œ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ì…ë‹ˆë‹¤.')
        st.markdown('3ï¸âƒ£ MATHQA : ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì˜µì…˜ ê°€ê²© ëª¨ë¸ë§ ë“± ê¸ˆìœµ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ìˆ˜ë¦¬ì  ë¬¸ì œë¥¼ ì˜ í•´ê²°í•˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ì…ë‹ˆë‹¤.')
        st.write('')
        st.markdown('<h5>ê´€ë ¨ ë¬¸ì˜ì‚¬í•­</h5>', unsafe_allow_html=True)
        st.markdown('í‰ê°€ ì˜ˆì‹œ ë°ì´í„°ì…‹ê³¼ Chatgpt ì‚¬ìš© ê´€ë ¨ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ anstmdwn45@personaai.co.krë¡œ ì—°ë½ì£¼ì„¸ìš” ğŸ¤©')
        st.markdown('Made with â¤ï¸ by the awesome open-source community from all over ğŸŒ')
        st.write('')
        st.write('')
        st.write('')

    with tab2:
        code2 = '''
# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ë¡œë“œ
import openai

# 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (gpt-api key ì„¤ì •)
client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY", "API_KEY ì…ë ¥"))

# 3. ëª¨ë¸ ì¶”ë¡ ìˆ˜í–‰
messages = [
    {"role": "system", "content": 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.'},
    {"role": "user", "content": str(question)}
    ]

response = client.chat.completions.create(
    model=selected_option,
    messages=messages,
    max_tokens=4096) # ìµœëŒ€ 4k 

result = response.choices[0].message.content

'''
        code = '''
# 1. í•„ìš” ê°œë°œí™˜ê²½ ì„¤ì¹˜ (Colab, Jupyter)
!pip install openai

# 2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ë¡œë“œ
import openai
import os

# 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (gpt-api key ì„¤ì •)
openai.api_key = os.environ.get("OPENAI_API_KEY", "API_KEY ì…ë ¥")

# 4. openai playground í•™ìŠµ ë°ì´í„° ì—…ë¡œë“œ
def data_loader(train_file):
    with open(train_file, 'rb') as train_ft:
        training_response = openai.File.create(file=train_ft, purpose='fine-tune')
        return training_response['id']

# 5. gpt-3.5-turbo ë¯¸ì„¸ì¡°ì •
def gpt_finetuning(training_file_id):
    response = openai.FineTuningJob.create(
        training_file=training_file_id,
        model="gpt-3.5-turbo",  # ì—¬ê¸°ì„œ ì‚¬ìš©í•  ëª¨ë¸ëª…ì„ ì •í™•íˆ ì§€ì •í•˜ì„¸ìš”
        suffix="Finance_íŒ€ì´ë¦„",
        hyperparameters={
            "n_epochs": 3,  # ë°ì´í„° ë°˜ë³µ íšŸìˆ˜ / ì£¼ë¡œ 3~5ë¡œ ì„¤ì •
            "batch_size": 3,  # í•œ ë²ˆì˜ í•™ìŠµì— ì²˜ë¦¬í•  ë°ì´í„° ìˆ˜
            "learning_rate_multiplier": 0.3  # ëª¨ë¸ì˜ í•™ìŠµë¥ : ê²½ì‚¬í•˜ê°•ë²•ì„ í†µí•´ ëª¨ë¸ì´ ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” ë°©í–¥ì„ ì„¤ì •
        })
    return response

# ì˜ˆì‹œ ì‚¬ìš©ë²•
train_file = 'ë°ì´í„°ì…‹ ê²½ë¡œ'
training_file_id = data_loader(train_file)
finetuning_response = gpt_finetuning(training_file_id)

print(finetuning_response)
        '''
        data = [{"messages": [{"role": "system", "content": "ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."}, {"role": "user", "content": "ë‹¤ìŒ ê¸ˆìœµ í—¤ë“œë¼ì¸ì˜ ì •ì„œëŠ” ë¬´ì—‡ì¸ê°€ìš”? ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ì¤‘ ì–´ëŠ ìª½ì¸ê°€ìš”?\ní…ìŠ¤íŠ¸:ë¯¸ë˜ì—ì…‹, 'í”„ë¦¬ë¯¸ì—„ ì»¤ë²„ë“œì½œ ì›”ë°°ë‹¹ ETF' 5ì¢… ê°œì¸ ëˆ„ì  ìˆœë§¤ìˆ˜ 1ì¡° ë„˜ì–´\nì •ë‹µ:"}, {"role": "assistant", "content": "í—¤ë“œë¼ì¸ì˜ ì •ì„œëŠ” ê¸ì •ì…ë‹ˆë‹¤"}]}]
        st.markdown('<h3>Evaluation Queue for the ğŸš€ Open Ko-LLM Leaderboard</h3>', unsafe_allow_html=True)
        st.markdown('1ï¸âƒ£ ê¸ˆìœµ ë„ë©”ì¸ ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ')
        with open('./fine-tuning dataset/finetune_training.jsonl', 'r') as f:
             file_contents = f.read()
        st.download_button(
        	label = 'ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë°›ê¸°',
        	data = file_contents,
        	file_name ='sample.jsonl',
        	mime ='application/json')
        st.markdown('2ï¸âƒ£ ChatGPTë¥¼ í™œìš©í•˜ì—¬ ë¯¸ì„¸ ì¡°ì •ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•')
        st.code(code, language='python')
        st.markdown('3ï¸âƒ£ ë§Œì•½ì— ë°ì´í„° ë° ëª¨ë¸ì„ ì—…ë¡œë“œ í•˜ì˜€ëŠ”ë°, ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤ë©´ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ë³´ì„¸ìš”')
        st.markdown('âš ï¸ gpt modelì„ íŒŒì¸íŠœë‹ í•˜ê¸°ìœ„í•´ì„œëŠ” ìœ„ì—ì„œ ì •ì˜í•œ Chat-Completion ë°ì´í„° í˜•ì‹ì„ ìœ ì§€í•´ì•¼í•©ë‹ˆë‹¤.â—')
        st.code(data,language='json')
        st.markdown('âš ï¸ Fine Tuningì„ í•œ ëª¨ë¸ ê³„ì •ì˜ APIë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ì§€ ì•Šì„ê²½ìš° ì œëŒ€ë¡œ ëœ í‰ê°€ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.â—')
        st.markdown('âš ï¸ OpenAPI Keyë¥¼ í™•ì¸í•´ë³´ì„¸ìš”. ì¢…ì¢… API Keyë¥¼ ì˜ëª» ì…ë ¥í•œ ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ğŸ¤£')
        st.markdown('')
        st.markdown('4ï¸âƒ£ ëª¨ë¸ í‰ê°€ ë°©ë²•ì€ ì•„ë˜ ë©”ë‰´ì–¼ ëŒ€ë¡œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤.')
        st.markdown('â€¢ ì…ë ¥ 1ì„ í´ë¦­í•˜ì—¬ íŒŒì¸íŠœë‹ì„ ìˆ˜í–‰í•œ ëª¨ë¸ì´ë¦„ê³¼ OpenAI API Keyë¥¼ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤.')
        st.markdown('â€¢ ì…ë ¥ 2ë¥¼ í´ë¦­í•˜ì—¬ íŒ€ ì´ë¦„ê³¼ ëª¨ë¸ íƒ€ì…ì„ ì„¤ì •í•˜ëŠ”ë°, íŒ€ ì´ë¦„ì€ ìµœì¢… ëª¨ë¸ í‰ê°€ ê³¼ì •ì—ì„œ í•„ìš”í•œ ì‚¬í•­ì´ë‹ˆ ë°˜ë“œì‹œ ì…ë ¥í•´ì£¼ì„¸ìš” â—')
        st.markdown('â€¢ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ”ë° ëŒ€ì²´ë¡œ 10ë¶„ ì´ìƒ ì†Œìš” ë©ë‹ˆë‹¤ ğŸ˜Š ê·¸ ì‹œê°„ë™ì•ˆ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ êµ¬ì„±í•´ë³´ì„¸ìš” ')
        #st.markdown('â€¢ ì¶”ë¡ ì´ ëë‚˜ë©´ ì•„ë˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬, íŒŒì¸íŠœë‹ ëœ ChatGpt ëª¨ë¸ì˜ ì¶œë ¥ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
        st.markdown('5ï¸âƒ£ ë¯¸ì„¸ì¡°ì •ëœ ChatGPTë¥¼ í™œìš©í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•')
        st.code(code2, language='python')
        st.markdown('')

        
        with st.form(key='inference_form_1'):  # ê³ ìœ í•œ í‚¤ ë¶€ì—¬
            st.subheader('ğŸ“‹ ì¸í¼ëŸ°ìŠ¤ ê²°ê³¼ ìƒì„±')

            # í…ìŠ¤íŠ¸ ì…ë ¥ ìƒì
            col1, col2 = st.columns([0.54, 0.46])
            
            with col1:
                with st.expander('ì…ë ¥ 1'):
                    selected_option = st.text_input(
                        "ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.", 
                        placeholder='ì—¬ê¸°ì— ì…ë ¥í•´ì£¼ì„¸ìš”',
                        help='ëª¨ë¸ëª… ì˜ˆì‹œ ft:gpt-ëª¨ë¸ëª…:personal:íŒŒì¸íŠœë‹ ëª¨ë¸ëª…'
                    )
                    api_key = st.text_input(
                        label='OpenAPI Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.', 
                        max_chars=200, 
                        type='password',
                        placeholder='ì—¬ê¸°ì— ì…ë ¥í•´ì£¼ì„¸ìš”',
                        help='sk-xxxxxxxxxxxxxx'
                    )
                    
                    client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY", api_key))

            with col2:
                with st.expander('ì…ë ¥ 2'):
                    selected_option_name = st.text_input(
                        "ì†Œì† íŒ€ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.", 
                        placeholder='ë°˜ë“œì‹œ íŒ€ì´ë¦„-ì œì¶œì‹œê°„ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš” ex)í˜ë¥´ì†Œë‚˜-1130',
                        help = 'ex) ì „ë‚¨ëŒ€-15'
                    )
                    selected_option_type = st.text_input(
                        "ëª¨ë¸ íƒ€ì…",
                        ("ğŸŸ¢ gpt-3.5-turbo")
                    )


            # í¼ ì œì¶œ ë²„íŠ¼
            submit_button = st.form_submit_button('ëª¨ë¸ ì œì¶œí•˜ê¸°!')    

            if submit_button:
                # if not selected_option.startswith("ft:gpt-3.5-turbo"):
                if "gpt-3.5-turbo" not in selected_option:
                    st.error("ëª¨ë¸ëª…ì„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”. gpt-3.5-turbo ëª¨ë¸ë§Œ ì‚¬ìš©ê°€ëŠ¥ í•©ë‹ˆë‹¤")
                else:
                    with st.spinner():
                        client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY", api_key)) 
                        df_questions = pd.read_json('./streamlit/FinBench.jsonl', lines=True)
                        single_turn_outputs = []
                        for question in df_questions['questions']:
                            messages = [
                                {"role": "system", "content": 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.'},
                                {"role": "user", "content": str(question)}]
                            response = client.chat.completions.create(
                                model=selected_option,
                                messages=messages,
                                max_tokens=4096
                            )
                            single_turn_outputs.append([response.choices[0].message.content])

                        df_output = pd.DataFrame({
                            'id': df_questions['id'],
                            'category': df_questions['category'],
                            'questions': df_questions['questions'],
                            'outputs': single_turn_outputs,
                            'references': df_questions['references']
                        })

                        json_output = df_output.to_json(orient='records', lines=True, force_ascii=False)
                        st.session_state['json_output'] = json_output
                        st.session_state['selected_option_name'] = selected_option_name
                        upload_to_github(github_token, "NUMCHCOMCH/Kor_Finance-leaderboard", f"./data/{st.session_state['selected_option_name'].replace('/', '_')}.jsonl", json_output)

        #if 'json_output' in st.session_state:
        #    st.download_button(
        #        label='ì¶”ë¡  ê²°ê³¼ ë‹¤ìš´ë¡œë“œ í•˜ê¸°',
        #        data=st.session_state['json_output'],
        #        file_name=f"{st.session_state['selected_option_name'].replace('/', '_')}.jsonl",
        #        mime='text/json'
        #    )
         
    with tab3:
        st.markdown('<h5> ğŸ‘©â€âœˆï¸ ê¸ˆìœµ LLM ë¦¬ë”ë³´ë“œ í‰ê°€ ê·œì¹™</h5>', unsafe_allow_html=True)
        st.markdown('1ï¸âƒ£ ì ìˆ˜ ì‚°ì¶œì€ 3ê°€ì§€ ì§€í‘œ(MMLU_F, FIQUSA, MATHQA) ì ìˆ˜ì˜ í‰ê· ìœ¼ë¡œ ì‚°ì¶œí•©ë‹ˆë‹¤.')
        st.markdown('2ï¸âƒ£ MMLU_Fì™€ MATHQAì˜ ê²½ìš° ê¸ˆìœµ ë„ë©”ì¸ ì§€ì‹ê³¼ ë³µì¡í•œ ì¶”ë¡ ì´ í•„ìš”í•˜ë¯€ë¡œ ê°€ì‚°ì ì´ ìˆìŠµë‹ˆë‹¤.ğŸ˜˜')
        st.markdown('3ï¸âƒ£ ì›í™œí•œ ì„œë¹„ìŠ¤ ê°œë°œì„ ìœ„í•´ì„œ ëª¨ë¸ ì œì¶œì€ í•˜ë£¨ ìµœëŒ€ 2ë²ˆê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨â—ë§ˆì§€ë§‰ë‚ ì€ ì›í™œí•œ ì§„í–‰ì„ ìœ„í•´ 1ë²ˆë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ')

        # DataFrame ìƒì„±
        st.markdown('')
        st.subheader('ëª¨ë¸ ì¶”ë¡  ê²°ê³¼')
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ì§‘ê³„ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        category_scores = {}

        # ì „ì²´ ì‹±ê¸€ ì ìˆ˜ì™€ ë©€í‹° ì ìˆ˜ì˜ ë¦¬ìŠ¤íŠ¸
        total_single_scores = []

        file_path1 = './streamlit/Baseline_model.jsonl'
        file_path2 = './streamlit/finetuning_model.jsonl'
        file_path3 = './streamlit/AIë¼ì´í”„-2100.jsonl'
        file_path4 = './streamlit/AIë¼ì´í”„-2200.jsonl'
        file_path5 = './streamlit/ì´ë£¨ë§¤-2100.jsonl'
        file_path6 = './streamlit/ì´ë£¨ë§¤-2200.jsonl'
        file_path7 = './streamlit/í ë¦¬ì»¨ì ì‚¬ê³ -2200.jsonl'
        # file_path8 = './streamlit/AIë¼ì´í”„-2200.jsonl'
        file_path8 = './streamlit/ì´ë£¨ë§¤-0900.jsonl'
        file_path9 = './streamlit/í ë¦¬ì»¨ì ì‚¬ê³ -0900.jsonl'
        file_path10 = './streamlit/ì´ë£¨ë§¤-1000.jsonl'
        file_path11 = './streamlit/AIë¼ì´í”„-0900.jsonl'
        file_path12 = './streamlit/AIë¼ì´í”„-1100.jsonl'
        file_path13 = './streamlit/í ë¦¬ì»¨ì ì‚¬ê³ -1100.jsonl'




        def extract_team_and_number(filename):
            # íŒŒì¼ í™•ì¥ì ì œê±°
            base_name = os.path.splitext(filename)[0]

            # '-'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒ€ ì´ë¦„ê³¼ ì œì¶œ ë²ˆí˜¸ ë¶„ë¦¬
            parts = base_name.split('-')
            if len(parts) > 1:
                team_name = parts[0]
                submission_number = parts[1]  # '1930' ì¶”ì¶œ
                if re.match(r'^\d{4}$', submission_number):  # ì •í™•íˆ 4ìë¦¬ ìˆ«ìì¸ì§€ í™•ì¸
                    formatted_time = f"{submission_number[:2]}:{submission_number[2:]}"  # '19:30' í˜•ì‹ìœ¼ë¡œ ë³€ê²½
                    return team_name, formatted_time
                else:
                    return team_name, "00:00"  # ìˆ«ì í˜•ì‹ì´ ë§ì§€ ì•Šì„ ê²½ìš° "00:00"ìœ¼ë¡œ ë°˜í™˜
            else:
                # '-'ê°€ ì—†ëŠ” ê²½ìš° "00:00"ìœ¼ë¡œ ì˜¤ë¥˜ ì²˜ë¦¬
                return parts[0], "00:00"



        # ì§€ì •ëœ íŒ¨í„´ì— ë§ëŠ” ëª¨ë“  íŒŒì¼ì„ ì°¾ì•„ì„œ ì²˜ë¦¬
        def process_file_to_dataframe(file_path):
            category_scores = {} 
            with open(file_path, 'r', encoding='utf-8-sig') as file:  # 'utf-8-sig'ë¡œ ì¸ì½”ë”© ë³€ê²½
                for line in file:
                    item = json.loads(line)
                    category = item['category']
                    single_score = item['query_single']['judge_score']
        
                    if category not in category_scores:
                        category_scores[category] = []
                
                    category_scores[category].append(single_score)

            # ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            avg_scores = {category: (sum(scores) / len(scores)) if scores else 0 for category, scores in category_scores.items()}

            # MMLU_Fì™€ MATHQAì— ê°€ì¤‘ì¹˜ ì ìš©
            if 'MMLU_F' in avg_scores:
                avg_scores['MMLU_F'] *= 1.1
            if 'MATHQA' in avg_scores:
                avg_scores['MATHQA'] *= 1.1
    
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df = pd.DataFrame([avg_scores])
            
            # íŒŒì¼ ì´ë¦„ì—ì„œ íŒ€ ì´ë¦„ê³¼ ëª¨ë¸ ì œì¶œ ë²ˆí˜¸ ì¶”ì¶œ
            team_name, submission_number = extract_team_and_number(os.path.basename(file_path))
            df['íŒ€ì´ë¦„'] = team_name
            df['ëª¨ë¸ ì œì¶œì¼ì‹œ'] = submission_number
            df['AVG_Score'] = ((df['MMLU_F'] + df['FIQUSA'] + df['MATHQA'])/3).round(3)

            return df
        
        # ì†Œìˆ˜ì  í•œ ìë¦¬ë¡œ ì„¤ì •
        pd.options.display.float_format = "{:.1f}".format
        df1 = process_file_to_dataframe(file_path1)
        df2 = process_file_to_dataframe(file_path2)
        df3 = process_file_to_dataframe(file_path3)
        df4 = process_file_to_dataframe(file_path4)
        df5 = process_file_to_dataframe(file_path5)
        df6 = process_file_to_dataframe(file_path6)
        df7 = process_file_to_dataframe(file_path7)
        df8 = process_file_to_dataframe(file_path8)
        df9 = process_file_to_dataframe(file_path9)
        df10 = process_file_to_dataframe(file_path10)
        df11 = process_file_to_dataframe(file_path11)
        df12 = process_file_to_dataframe(file_path12)
        df13 = process_file_to_dataframe(file_path13)
        # df8 = process_file_to_dataframe(file_path4)

        df = pd.concat([df3,df4,df5,df6,df7]).sort_values('AVG_Score',ascending=False).reset_index(drop=True)
        yesterday =  datetime.datetime.now() - datetime.timedelta(days=1)
        df['ëª¨ë¸ ì œì¶œì¼ì‹œ'] = yesterday.strftime("%Y.%m.%d") + ' ' + df['ëª¨ë¸ ì œì¶œì¼ì‹œ']
        #df['ëª¨ë¸ ì œì¶œì¼ì‹œ'] = datetime.datetime.now().strftime("%Y.%m.%d") + ' ' + df['ëª¨ë¸ ì œì¶œì¼ì‹œ']
        df = df[['íŒ€ì´ë¦„','MMLU_F','FIQUSA','MATHQA','AVG_Score','ëª¨ë¸ ì œì¶œì¼ì‹œ']]
        data = pd.concat([df8,df9,df10,df11,df12,df13]).sort_values('AVG_Score',ascending=False).reset_index(drop=True)
        data['ëª¨ë¸ ì œì¶œì¼ì‹œ'] = datetime.datetime.now().strftime("%Y.%m.%d") + ' ' + data['ëª¨ë¸ ì œì¶œì¼ì‹œ']
        data = data[['íŒ€ì´ë¦„','MMLU_F','FIQUSA','MATHQA','AVG_Score','ëª¨ë¸ ì œì¶œì¼ì‹œ']]
        df = pd.concat([df,data]).sort_values('AVG_Score',ascending=False).reset_index(drop=True)
        df.index = df.index + 1
        df.index.name = 'ìˆœìœ„'
        st.dataframe(df,use_container_width=True)

def main():
    setup_basic()
    setup_about()
    
if __name__ == "__main__":
    main()
